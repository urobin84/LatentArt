{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or2KNAA0GILH"
   },
   "source": [
    "# **Penting**\n",
    "\n",
    "*   Pada Notebook ini, Anda hanya perlu mengerjakan code pada bagian **logic.py** saja. Anda tidak diwajibkan untuk mengubah atau menambahkan **app.py** yang digunakan untuk membangun interface Streamlit.\n",
    "*   Namun, jika Anda memiliki preferensi lain atau ingin mengubah struktur code pada logic ataupun pada interface Streamlit, itu **DIPERSILAHKAN** saja, tetapi pastikan untuk memenuhi kriteria yang telah ditetapkan pada intruksi submission\n",
    "*   Jika Anda tidak ingin mengubah apapun dan ingin mengikuti template, tugas Anda hanyalah melengkapi code yang rumpang pada bagian yang sudah ditandai \"________\" saja.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2GnD1QImBX2"
   },
   "source": [
    "# **Prepare Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T02:50:48.331126Z",
     "iopub.status.busy": "2026-02-26T02:50:48.330612Z",
     "iopub.status.idle": "2026-02-26T02:51:23.260430Z",
     "shell.execute_reply": "2026-02-26T02:51:23.259961Z"
    },
    "id": "0-WuMWt9hdbb"
   },
   "outputs": [],
   "source": [
    "!pip install -q pyngrok\n",
    "!pip install -q streamlit\n",
    "!pip install -q torch\n",
    "!pip install -q diffusers\n",
    "!pip install -q transformers\n",
    "!pip install -q streamlit_drawable_canvas==0.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:23.263009Z",
     "iopub.status.busy": "2026-02-26T02:51:23.262622Z",
     "iopub.status.idle": "2026-02-26T02:51:23.346097Z",
     "shell.execute_reply": "2026-02-26T02:51:23.345752Z"
    },
    "id": "cURIiO0Yh6gP"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "# import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILLV-lZ7mN5g"
   },
   "source": [
    "# **Streamlit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KES2DFp0qhCc"
   },
   "source": [
    "## logic.py (**Basic**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:23.349010Z",
     "iopub.status.busy": "2026-02-26T02:51:23.348814Z",
     "iopub.status.idle": "2026-02-26T02:51:48.945166Z",
     "shell.execute_reply": "2026-02-26T02:51:48.944818Z"
    },
    "id": "u8U0UVRHsKTS",
    "outputId": "21ad44a2-c563-44ef-ef81-9e851726d30d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting logic.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile logic.py\n",
    "import torch\n",
    "import gc\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline,\n",
    "    StableDiffusionInpaintPipeline,\n",
    "    StableDiffusionImg2ImgPipeline,\n",
    "    EulerAncestralDiscreteScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    DDIMScheduler\n",
    ")\n",
    "from PIL import Image, ImageFilter, ImageDraw\n",
    "import numpy as np\n",
    "\n",
    "# MODEL LOADER (OPTIMIZED FOR M1 MAC & DICODING CONVENTIONS)\n",
    "def load_models_cached():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "    print(f\"Loading models to {device} using {dtype}\")\n",
    "\n",
    "    pipe_txt2img = StableDiffusionPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\", \n",
    "        torch_dtype=dtype, \n",
    "        use_safetensors=False,\n",
    "        safety_checker=None,\n",
    "        requires_safety_checker=False\n",
    "    ).to(device)\n",
    "    pipe_txt2img.enable_attention_slicing()\n",
    "\n",
    "    pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-inpainting\", \n",
    "        torch_dtype=dtype, \n",
    "        use_safetensors=False,\n",
    "        safety_checker=None,\n",
    "        requires_safety_checker=False\n",
    "    ).to(device)\n",
    "    pipe_inpaint.enable_attention_slicing()\n",
    "\n",
    "    return pipe_txt2img, pipe_inpaint\n",
    "\n",
    "def flush_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def set_scheduler(pipe, name):\n",
    "    if name == \"Euler A\":\n",
    "        pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "    elif name == \"DPM++\":\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    elif name == \"DDIM\":\n",
    "        pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    return pipe\n",
    "\n",
    "def generate_image(pipe, prompt, neg_prompt, seed, steps, cfg, num_images=1, scheduler_name=\"Euler A\"):\n",
    "    device = pipe.device\n",
    "    pipe = set_scheduler(pipe, scheduler_name)\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "    # --- STAGE 1: BASE GENERATION ---\n",
    "    base_output = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=neg_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg,\n",
    "        num_images_per_prompt=num_images,\n",
    "        generator=generator\n",
    "    )\n",
    "    base_images = base_output.images\n",
    "\n",
    "    # --- STAGE 2: REFINER (Refinement Logic) ---\n",
    "    pipe_refiner = StableDiffusionImg2ImgPipeline(\n",
    "        vae=pipe.vae,\n",
    "        text_encoder=pipe.text_encoder,\n",
    "        tokenizer=pipe.tokenizer,\n",
    "        unet=pipe.unet,\n",
    "        scheduler=pipe.scheduler,\n",
    "        feature_extractor=pipe.feature_extractor,\n",
    "        safety_checker=None\n",
    "    ).to(device)\n",
    "\n",
    "    result = pipe_refiner(\n",
    "        prompt=[prompt] * len(base_images),\n",
    "        negative_prompt=[neg_prompt] * len(base_images),\n",
    "        image=base_images,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg,\n",
    "        generator=generator,\n",
    "        strength=0.8\n",
    "    ).images\n",
    "\n",
    "    return result\n",
    "\n",
    "def inpaint_engine(pipe, image, mask, prompt, negative_prompt=\"\", seed=9, is_outpainting=False):\n",
    "    device = pipe.device\n",
    "    strength = 1.0 if is_outpainting else 0.9\n",
    "    steps = 50 if is_outpainting else 30\n",
    "\n",
    "    if image.mode != \"RGB\": image = image.convert(\"RGB\")\n",
    "    if mask.mode != \"L\": mask = mask.convert(\"L\")\n",
    "    image = image.resize((512, 512))\n",
    "    mask = mask.resize((512, 512), resample=Image.NEAREST)\n",
    "\n",
    "    generator = torch.Generator(device=device).manual_seed(seed)\n",
    "    result = pipe(\n",
    "        prompt=prompt, \n",
    "        negative_prompt=negative_prompt,\n",
    "        image=image, \n",
    "        mask_image=mask, \n",
    "        strength=strength,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=7.5,\n",
    "        generator=generator\n",
    "    ).images[0]\n",
    "    return result\n",
    "\n",
    "def prepare_outpainting(image, direction=\"right\", expand_pixels=256):\n",
    "    init_image = image.convert(\"RGB\").resize((512, 512))\n",
    "    w, h = init_image.size\n",
    "    \n",
    "    if direction == \"zoom_out\":\n",
    "        padding_scale = (w + expand_pixels) / w\n",
    "        new_width = int(w * padding_scale)\n",
    "        new_height = int(h * padding_scale)\n",
    "        canvas = Image.new(\"RGB\", (new_width, new_height), (0, 0, 0))\n",
    "        x = (new_width - w) // 2\n",
    "        y = (new_height - h) // 2\n",
    "        canvas.paste(init_image, (x, y))\n",
    "        mask = Image.new(\"L\", (new_width, new_height), 255)\n",
    "        mask_content = Image.new(\"L\", (w, h), 0)\n",
    "        mask.paste(mask_content, (x, y))\n",
    "    else:\n",
    "        if direction == \"left\":\n",
    "            new_size = (w + expand_pixels, h)\n",
    "            paste_pos = (expand_pixels, 0)\n",
    "        elif direction == \"right\":\n",
    "            new_size = (w + expand_pixels, h)\n",
    "            paste_pos = (0, 0)\n",
    "        elif direction == \"up\":\n",
    "            new_size = (w, h + expand_pixels)\n",
    "            paste_pos = (0, expand_pixels)\n",
    "        elif direction == \"down\":\n",
    "            new_size = (w, h + expand_pixels)\n",
    "            paste_pos = (0, 0)\n",
    "        else:\n",
    "            new_size = (w + expand_pixels, h)\n",
    "            paste_pos = (0, 0)\n",
    "\n",
    "        canvas = Image.new(\"RGB\", new_size, (0, 0, 0))\n",
    "        canvas.paste(init_image, paste_pos)\n",
    "        mask = Image.new(\"L\", new_size, 255)\n",
    "        mask_content = Image.new(\"L\", (w, h), 0)\n",
    "        mask.paste(mask_content, paste_pos)\n",
    "    \n",
    "    return canvas.resize((512, 512)), mask.resize((512, 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:48.952788Z",
     "iopub.status.busy": "2026-02-26T02:51:48.952548Z",
     "iopub.status.idle": "2026-02-26T02:51:48.955170Z",
     "shell.execute_reply": "2026-02-26T02:51:48.954731Z"
    },
    "id": "DIp2ZAP3Uwhy",
    "outputId": "fef267ef-941f-48c3-8760-31a6ea7bf5f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to logic.py\n"
     ]
    }
   ],
   "source": [
    "# Appending logic (Handled in main logic cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axNesBDoq66a"
   },
   "source": [
    "## logic.py (**Skilled**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:48.957268Z",
     "iopub.status.busy": "2026-02-26T02:51:48.957141Z",
     "iopub.status.idle": "2026-02-26T02:51:48.960597Z",
     "shell.execute_reply": "2026-02-26T02:51:48.960254Z"
    },
    "id": "lOdmPzkuU8_1",
    "outputId": "049732ab-5965-4d50-a09f-4dd8534a22d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to logic.py\n"
     ]
    }
   ],
   "source": [
    "# Appending logic (Handled in main logic cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSiw_ZPorC64"
   },
   "source": [
    "## logic.py (**Advanced**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:48.962295Z",
     "iopub.status.busy": "2026-02-26T02:51:48.962171Z",
     "iopub.status.idle": "2026-02-26T02:51:48.966135Z",
     "shell.execute_reply": "2026-02-26T02:51:48.965857Z"
    },
    "id": "IYrxx8mkVEa6",
    "outputId": "8ef480bb-c258-47d6-faa8-0abf99c231d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to logic.py\n"
     ]
    }
   ],
   "source": [
    "# Appending logic (Handled in main logic cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lldtOVOaqnt1"
   },
   "source": [
    "## app.py\n",
    "Anda **TIDAK perlu mengubah atau menambahkan** apapun pada file **app.py** ini, cukup **jalankan** saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:51:48.968212Z",
     "iopub.status.busy": "2026-02-26T02:51:48.968012Z",
     "iopub.status.idle": "2026-02-26T02:52:06.353043Z",
     "shell.execute_reply": "2026-02-26T02:52:06.349913Z"
    },
    "id": "kixif86yhu0s",
    "outputId": "2add424a-b27b-449d-d9a1-deb144916f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from streamlit_drawable_canvas import st_canvas\n",
    "import logic\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "st.set_page_config(page_title=\"StudioAI\", layout=\"wide\", page_icon=\"üé®\")\n",
    "\n",
    "@st.cache_resource\n",
    "def get_models():\n",
    "    return logic.load_models_cached()\n",
    "\n",
    "try:\n",
    "    pipe_txt2img, pipe_inpaint = get_models()\n",
    "except Exception as e:\n",
    "    st.error(f\"Error loading models: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "st.title(\"üé® StudioAI: Image Generation Suite\")\n",
    "\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Parameters\")\n",
    "    steps = st.slider(\"Quality Steps\", 15, 50, 30)\n",
    "    cfg = st.slider(\"Creativity (CFG)\", 1.0, 20.0, 7.5)\n",
    "    seed = st.number_input(\"Seed Control\", value=222)\n",
    "    scheduler_name = st.selectbox(\"Scheduler\", [\"Euler A\", \"DPM++\", \"DDIM\"])\n",
    "    num_images = st.slider(\"Batch Size\", 1, 4, 4)\n",
    "\n",
    "    if st.button(\"üßπ Flush RAM\"):\n",
    "        logic.flush_memory()\n",
    "        st.toast(\"Memory Cleared!\")\n",
    "\n",
    "tab_gen, tab_edit = st.tabs([\"‚ú® GENERATE\", \"üõ†Ô∏è EDIT\"])\n",
    "\n",
    "with tab_gen:\n",
    "    c1, c2 = st.columns([1, 1], gap=\"large\")\n",
    "    with c1:\n",
    "        st.subheader(\"Input Blueprint\")\n",
    "        with st.form(key=\"gen_form\"):\n",
    "            prompt = st.text_area(\"Prompt\", \"an astronaut on the moon with planet earth visible in the background, highly detailed, 8k resolution\", height=150)\n",
    "            neg_prompt = st.text_input(\"Negative Prompt\", \"photorealistic, realistic, photograph, 3d render, messy, blurry, low quality, bad art, ugly, sketch, grainy, unfinished, chromatic aberration\")\n",
    "            submit_gen = st.form_submit_button(\"üöÄ Initialize Generation\", type=\"primary\")\n",
    "\n",
    "        if submit_gen:\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                logic.flush_memory()\n",
    "                generated_list = logic.generate_image(pipe_txt2img, prompt, neg_prompt, seed, steps, cfg, num_images, scheduler_name)\n",
    "                st.session_state['generated_images'] = generated_list\n",
    "                if generated_list: st.session_state['current_image'] = generated_list[0]\n",
    "            st.rerun()\n",
    "\n",
    "    with c2:\n",
    "        st.subheader(\"Visual Output (2x2 Grid)\")\n",
    "        if 'generated_images' in st.session_state:\n",
    "            imgs = st.session_state['generated_images']\n",
    "            if len(imgs) > 1:\n",
    "                cols = st.columns(2)\n",
    "                for idx, img in enumerate(imgs):\n",
    "                    with cols[idx % 2]:\n",
    "                        st.image(img, caption=f\"Variant #{idx+1}\", use_container_width=True)\n",
    "                        if st.button(f\"Edit #{idx+1}\", key=f\"sel_{idx}\"):\n",
    "                             st.session_state['current_image'] = img\n",
    "                             st.toast(f\"‚úÖ Image #{idx+1} Selected!\")\n",
    "            elif len(imgs) == 1:\n",
    "                st.image(imgs[0], caption=\"Single Result\", use_container_width=True)\n",
    "        else:\n",
    "            st.info(\"üëà Enter your prompt on the left.\")\n",
    "\n",
    "with tab_edit:\n",
    "    if 'current_image' in st.session_state:\n",
    "        source_img = st.session_state['current_image'].resize((512, 512))\n",
    "        mode = st.radio(\"Tool Select:\", [\"Inpaint\", \"Outpaint\"], horizontal=True)\n",
    "        if mode == \"Inpaint\":\n",
    "            col_tools, col_result = st.columns([1, 1])\n",
    "            if 'canvas_key' not in st.session_state: st.session_state['canvas_key'] = 0\n",
    "            with col_tools:\n",
    "                st.subheader(\"‚úçÔ∏è Draw Mask\")\n",
    "                canvas_result = st_canvas(fill_color=\"rgba(255, 255, 255, 1.0)\", stroke_width=20, stroke_color=\"#FFFFFF\",\n",
    "                    background_image=source_img, height=512, width=512, drawing_mode=\"freedraw\", key=f\"canvas_{st.session_state['canvas_key']}\")\n",
    "            with col_result:\n",
    "                st.subheader(\"Inpaint Parameters\")\n",
    "                with st.form(\"inpaint_input\"):\n",
    "                    edit_prompt = st.text_input(\"Modify with...\", \"a detailed broken satellite floating in space, high resolution, cinematic, sharp focus\")\n",
    "                    inpaint_seed = st.number_input(\"Seed\", value=9)\n",
    "                    submit_inpaint = st.form_submit_button(\"‚ö° Execute\", type=\"primary\")\n",
    "                if submit_inpaint:\n",
    "                    if canvas_result.image_data is not None and np.max(canvas_result.image_data) > 0:\n",
    "                        with st.spinner(\"Inpainting...\"):\n",
    "                            mask_data = canvas_result.image_data[:, :, 3]\n",
    "                            mask_data[mask_data > 0] = 255\n",
    "                            mask_image = Image.fromarray(mask_data.astype('uint8'), mode='L')\n",
    "                            res_img = logic.inpaint_engine(pipe_inpaint, source_img, mask_image, edit_prompt, seed=inpaint_seed)\n",
    "                            st.session_state['current_image'] = res_img\n",
    "                            st.session_state['canvas_key'] += 1\n",
    "                            st.rerun()\n",
    "        else:\n",
    "            c_out_1, c_out_2 = st.columns([1, 1])\n",
    "            with c_out_1: st.image(source_img, use_container_width=True)\n",
    "            with c_out_2:\n",
    "                with st.form(\"outpaint_input\"):\n",
    "                    direction = st.selectbox(\"Expansion\", [\"zoom_out\", \"right\", \"left\", \"up\", \"down\"])\n",
    "                    out_prompt = st.text_input(\"Background prompt...\", \"vast cosmic landscape, stars\")\n",
    "                    submit_outpaint = st.form_submit_button(\"üîç Expand\", type=\"primary\")\n",
    "                if submit_outpaint:\n",
    "                    with st.spinner(\"Expanding...\"):\n",
    "                        c_ready, m_ready = logic.prepare_outpainting(source_img, direction=direction)\n",
    "                        res = logic.inpaint_engine(pipe_inpaint, c_ready, m_ready, out_prompt, seed=9, is_outpainting=True)\n",
    "                        st.session_state['current_image'] = res\n",
    "                        st.rerun()\n",
    "    else: st.info(\"üëà Generate an image first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l0v3epbkmkVx"
   },
   "source": [
    "# **Menggunakan *Ngrok* Untuk Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaneaH57DFlh"
   },
   "source": [
    "## **Konfigurasi Autentikasi Ngrok dan Menjalankan Aplikasi Streamlit**\n",
    "Cell ini digunakan untuk mengatur *authentication token Ngrok* dan menjalankan aplikasi Streamlit secara lokal. Token diperlukan agar *Ngrok* dapat membuat tunnel dengan akun pengguna. Setelah token diatur, aplikasi Streamlit dijalankan menggunakan subprocess sehingga server lokal aktif di background.\n",
    "\n",
    "Apabila Anda belum mengetahui cara mendapatkan *authentication token Ngrok* milik Anda sendiri, silahkan baca pada bagian **tips and tricks submission**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:52:06.386763Z",
     "iopub.status.busy": "2026-02-26T02:52:06.369306Z",
     "iopub.status.idle": "2026-02-26T02:52:06.394831Z",
     "shell.execute_reply": "2026-02-26T02:52:06.394401Z"
    },
    "id": "AlnsPa6Fhvwa",
    "outputId": "89a01497-f66c-4cc9-a6ea-3fac96c3a8f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Streamlit sedang dijalankan di background...\n"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "\n",
    "# Mengambil token yang kamu simpan dengan nama 'NG_TOKEN' di Secrets Colab\n",
    "auth_token = userdata.get('NG_TOKEN')\n",
    "\n",
    "# Konfigurasi Ngrok\n",
    "ngrok.set_auth_token(auth_token)\n",
    "\n",
    "# Menjalankan Streamlit di background\n",
    "# Pastikan file app.py dan logic.py sudah dibuat sebelumnya\n",
    "subprocess.Popen([\"streamlit\", \"run\", \"app.py\"])\n",
    "print(\"Server Streamlit sedang dijalankan di background...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yJzrhahDzUC"
   },
   "source": [
    "## **Membuat Public URL**\n",
    "Cell ini membuat *tunnel Ngrok* ke port lokal tempat Streamlit berjalan (default: 8501). *Ngrok* kemudian menghasilkan public URL yang bisa diakses dari internet, sehingga aplikasi Streamlit dapat dibuka tanpa harus berada di jaringan lokal yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2026-02-26T02:52:06.397975Z",
     "iopub.status.busy": "2026-02-26T02:52:06.397763Z",
     "iopub.status.idle": "2026-02-26T02:52:06.399888Z",
     "shell.execute_reply": "2026-02-26T02:52:06.399507Z"
    },
    "id": "wHCuib8dh8Ti",
    "outputId": "aaad21da-7bcd-4dab-f843-9b8a627db067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 9371 Feb 27 04:15 app.py\n",
      "-rw-r--r-- 1 root root 5401 Feb 27 04:15 logic.py\n",
      "https://maddeningly-subfastigiated-maryland.ngrok-free.dev\n"
     ]
    }
   ],
   "source": [
    "!ls -l app.py logic.py\n",
    "\n",
    "public_url = ngrok.connect(8501).public_url\n",
    "print(public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r9Iro5nD6B4"
   },
   "source": [
    "Apabila Anda mengalami limit endpoint usage pada Ngrok, jalankan hidden cell di bawah ini!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me8GqKY1EE_A"
   },
   "source": [
    "## **Menutup Semua Tunnel Ngrok yang Aktif**\n",
    "Cell ini digunakan untuk menghentikan seluruh koneksi Ngrok yang masih aktif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-26T02:52:06.402376Z",
     "iopub.status.busy": "2026-02-26T02:52:06.402181Z",
     "iopub.status.idle": "2026-02-26T02:52:06.406053Z",
     "shell.execute_reply": "2026-02-26T02:52:06.405567Z"
    },
    "id": "b0118cc9"
   },
   "outputs": [],
   "source": [
    "#ngrok.kill()\n",
    "#print(\"All active ngrok tunnels have been closed.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "me8GqKY1EE_A"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}