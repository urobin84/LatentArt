{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0PGSLdyror"
      },
      "source": [
        "# Project LatentArt: LatentArt Submission\n",
        "## Level: ADVANCED\n",
        "\n",
        "This notebook documents the implementation and experimentation for the Image Generation Submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7qBoxz4yrou"
      },
      "source": [
        "### Colab Initialization\n",
        "This cell automatically mounts Google Drive and installs requirements if running in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "github_init_cell",
        "outputId": "74a3c828-99ca-4784-874d-b706abfa2abb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"\ud83d\ude80 Running in Google Colab\\n\")\n",
        "    \n",
        "    GITHUB_TOKEN = \"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\"\n",
        "    GITHUB_USER = \"urobin84\"\n",
        "    REPO_NAME = \"LatentArt\"\n",
        "    \n",
        "    # Attempt clone using x-access-token (standard for fine-grained PAT)\n",
        "    if not os.path.exists(f'/content/{REPO_NAME}'):\n",
        "        print(f\"\ud83d\udcc2 Cloning {REPO_NAME}...\")\n",
        "        clone_url = f\"https://x-access-token:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\"\n",
        "        !git clone {clone_url} /content/{REPO_NAME}\n",
        "    \n",
        "    if os.path.exists(f'/content/{REPO_NAME}'):\n",
        "        %cd /content/{REPO_NAME}\n",
        "        !git config --global user.name \"{GITHUB_USER}\"\n",
        "        !git config --global user.email \"{GITHUB_USER}@users.noreply.github.com\"\n",
        "        !pip install -r requirements.txt\n",
        "        print(\"\\n\u2705 Initialization Success!\")\n",
        "    else:\n",
        "        print(f\"\\n\u274c CLONE FAILED!\")\n",
        "        print(\"Manual fix: Check if your PAT has 'repo' permissions or the repo name is correct.\")\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"\ud83c\udfe0 Running locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKaIP9bnyrow"
      },
      "source": [
        "### Setup Environment & Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "cXSf53Rcyrow",
        "outputId": "f7c1a7b0-b6d6-4a4b-f893-c4cc1e8542b2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import gc\n",
        "import os\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline, StableDiffusionImg2ImgPipeline, EulerAncestralDiscreteScheduler\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"Checking environment...\")\n",
        "if 'google.colab' in sys.modules:\n",
        "    src_path = '/content/LatentArt/src'\n",
        "    if not os.path.exists(src_path):\n",
        "         # Try relative if clone path differs for some reason\n",
        "         src_path = os.path.abspath('src')\n",
        "else:\n",
        "    src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "\n",
        "print(f\"Targeting src at: {src_path}\")\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "\n",
        "try:\n",
        "    from utils import get_device, clear_memory\n",
        "    device = get_device()\n",
        "    print(f\"\u2705 Module 'utils' loaded successfully!\")\n",
        "    print(f\"Using device: {device}\")\n",
        "except ImportError as e:\n",
        "    print(f\"\u274c ERROR: {e}\")\n",
        "    print(\"Printing sys.path for debugging:\")\n",
        "    for p in sys.path: print(f\"  - {p}\")\n",
        "    print(\"Available files in current directory:\")\n",
        "    print(os.listdir())\n",
        "\n",
        "def load_scheduler(pipeline, scheduler_name=\"Euler A\"):\n",
        "    if scheduler_name == \"Euler A\":\n",
        "        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
        "    print(f\"Scheduler set to: {scheduler_name}\")\n",
        "\n",
        "negative_prompt = \"photorealistic, realistic, photograph, 3d render, messy, blurry, low quality, bad art, ugly, sketch, grainy, unfinished, chromatic aberration\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOFUC9bpyrow"
      },
      "source": [
        "### Kriteria 1: Text-to-Image (T2I)\n",
        "#### Basic: Simple Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMxc4DTkyrox"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe_t2i = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "load_scheduler(pipe_t2i, \"Euler A\")\n",
        "\n",
        "prompt = \"A futuristic city in the style of cyberpunk, vivid neon lights, high detail\"\n",
        "seed = 222\n",
        "generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "image = pipe_t2i(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "os.makedirs(\"../outputs\", exist_ok=True)\n",
        "image.save(\"../outputs/basic_t2i.png\")\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmWt4EWyrox"
      },
      "source": [
        "#### Skilled: Experimentation (Guidance Scale & Steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PDoxdeyrox"
      },
      "outputs": [],
      "source": [
        "# Experimentation on Guidance Scale (3-20) and Steps (10-50)\n",
        "guidance_scales = [3, 7, 15, 20]\n",
        "inference_steps = [10, 30, 50]\n",
        "exp_prompt = \"A majestic forest with magical glowing plants, digital art style\"\n",
        "\n",
        "fig, axes = plt.subplots(len(inference_steps), len(guidance_scales), figsize=(20, 15))\n",
        "\n",
        "for i, steps in enumerate(inference_steps):\n",
        "    for j, scale in enumerate(guidance_scales):\n",
        "        print(f\"Generating with Steps: {steps}, Scale: {scale}\")\n",
        "        generator = torch.Generator(device=device).manual_seed(222)\n",
        "        img = pipe_t2i(\n",
        "            prompt=exp_prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=scale,\n",
        "            generator=generator\n",
        ").images[0]\n",
        "        img.save(f\"../outputs/exp_steps{steps}_gs{scale}.png\")\n",
        "        axes[i, j].imshow(img)\n",
        "        axes[i, j].set_title(f\"Steps: {steps}, GS: {scale}\")\n",
        "        axes[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6xojAwNyroy"
      },
      "source": [
        "#### Advanced: Two-Stage Generation (Base + Refiner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsduNuMIyroy"
      },
      "outputs": [],
      "source": [
        "# Load Img2Img for refinement phase\n",
        "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Stage 1: Base Generation\n",
        "generator = torch.Generator(device=device).manual_seed(222)\n",
        "base_image = pipe_t2i(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, intricate armor\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "# Stage 2: Refinement (Denoising 0.8)\n",
        "refined_image = pipe_img2img(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, extreme armor detail, 4k, masterpiece\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=base_image.resize((768, 768)),\n",
        "    strength=0.8,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=8.0,\n",
        "    generator=torch.Generator(device=device).manual_seed(222)\n",
        ").images[0]\n",
        "\n",
        "refined_image.save(\"../outputs/advanced_refined.png\")\n",
        "refined_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaP5-DGSyroy"
      },
      "source": [
        "### Kriteria 2: Inpainting & Outpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nuMwAb_yroy"
      },
      "outputs": [],
      "source": [
        "inpaint_model_id = \"runwayml/stable-diffusion-inpainting\"\n",
        "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    inpaint_model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Manual Masking Demo\n",
        "init_image = Image.new(\"RGB\", (512, 512), (100, 100, 100)) # Grey background\n",
        "mask_image = Image.new(\"RGB\", (512, 512), (0, 0, 0)) # Black mask (do not change)\n",
        "draw = ImageDraw.Draw(mask_image)\n",
        "draw.rectangle([128, 128, 384, 384], fill=\"white\") # White area = change this!\n",
        "\n",
        "generator_inpaint = torch.Generator(device=device).manual_seed(9)\n",
        "\n",
        "inpainted_result = pipe_inpaint(\n",
        "    prompt=\"A majestic golden phoenix bird rising from flames\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=init_image,\n",
        "    mask_image=mask_image,\n",
        "    num_inference_steps=30,\n",
        "    generator=generator_inpaint\n",
        ").images[0]\n",
        "\n",
        "inpainted_result.save(\"../outputs/inpainted_result.png\")\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,3,1); plt.imshow(init_image); plt.title(\"Init\")\n",
        "plt.subplot(1,3,2); plt.imshow(mask_image); plt.title(\"Mask\")\n",
        "plt.subplot(1,3,3); plt.imshow(inpainted_result); plt.title(\"Result\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSEvkGqyroy"
      },
      "source": [
        "#### Zoom-Out (Outpainting) Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gJ71u0Jyroz"
      },
      "outputs": [],
      "source": [
        "def outpaint_prepare(image, pixels=128):\n",
        "    w, h = image.size\n",
        "    new_w = w + pixels\n",
        "    canvas = Image.new(\"RGB\", (new_w, h), (255, 255, 255))\n",
        "    canvas.paste(image, (0, 0))\n",
        "\n",
        "    mask = Image.new(\"RGB\", (new_w, h), (0, 0, 0))\n",
        "    mask_draw = ImageDraw.Draw(mask)\n",
        "    mask_draw.rectangle([w, 0, new_w, h], fill=\"white\")\n",
        "\n",
        "    return canvas, mask\n",
        "\n",
        "source_img = Image.open(\"../outputs/basic_t2i.png\").resize((512, 512))\n",
        "canvas, mask = outpaint_prepare(source_img)\n",
        "\n",
        "outpainted = pipe_inpaint(\n",
        "    prompt=\"A futuristic neon city street extending into the distance, cybernetic details\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=canvas,\n",
        "    mask_image=mask,\n",
        "    num_inference_steps=30,\n",
        "    generator=torch.Generator(device=device).manual_seed(9)\n",
        ").images[0]\n",
        "\n",
        "outpainted.save(\"../outputs/outpainted_result.png\")\n",
        "outpainted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIuoXnxeyroz"
      },
      "source": [
        "### Kriteria 3: Streamlit Interface Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjVrWV-iyroz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# Directly append the absolute Colab path and the exact relative path for local Jupyter\n",
        "colab_path = '/content/LatentArt/src'\n",
        "local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if os.path.exists(colab_path) and colab_path not in sys.path:\n",
        "    sys.path.append(colab_path)\n",
        "elif os.path.exists(local_path) and local_path not in sys.path:\n",
        "    sys.path.append(local_path)\n",
        "print(\"Streamlit setup would use the following structure in a .py file:\")\n",
        "print(\"\"\"\n",
        "import streamlit as st\n",
        "from streamlit_drawable_canvas import st_canvas\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "st.set_page_config(layout='wide')\n",
        "tab1, tab2 = st.tabs(['Text-to-Image', 'Inpaint & Outpaint'])\n",
        "\n",
        "with tab1:\n",
        "    # Batching logic 2x2 grid\n",
        "    pass\n",
        "\n",
        "with tab2:\n",
        "    # Canvas for masking logic\n",
        "    pass\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}