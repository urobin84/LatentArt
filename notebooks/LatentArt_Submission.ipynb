{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0PGSLdyror"
      },
      "source": [
        "# Project LatentArt: LatentArt Submission\n",
        "## Level: ADVANCED\n",
        "\n",
        "This notebook documents the implementation and experimentation for the Image Generation Submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7qBoxz4yrou"
      },
      "source": [
        "### Colab Initialization\n",
        "This cell automatically mounts Google Drive and installs requirements if running in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "github_init_cell"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running in Google Colab\\n\")\n",
        "    \n",
        "    GITHUB_TOKEN = \"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\"\n",
        "    GITHUB_USER = \"urobin84\"\n",
        "    REPO_NAME = \"LatentArt\"\n",
        "    \n",
        "    # Clone if not exists\n",
        "    if not os.path.exists(f'/content/{REPO_NAME}'):\n",
        "        !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git /content/{REPO_NAME}\n",
        "    \n",
        "    %cd /content/{REPO_NAME}\n",
        "    \n",
        "    # Configure Git\n",
        "    !git config --global user.name \"{GITHUB_USER}\"\n",
        "    !git config --global user.email \"{GITHUB_USER}@users.noreply.github.com\"\n",
        "    \n",
        "    # Install deps\n",
        "    !pip install -r requirements.txt\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running locally\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKaIP9bnyrow"
      },
      "source": [
        "### Setup Environment & Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "cXSf53Rcyrow",
        "outputId": "0a265941-7568-4b65-e0ea-5adb0b0061f2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import gc\n",
        "import os\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline, StableDiffusionImg2ImgPipeline, EulerAncestralDiscreteScheduler\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up paths based on environment\n",
        "if 'google.colab' in sys.modules:\n",
        "    # In Colab, the repo is at /content/LatentArt/src\n",
        "    src_path = '/content/LatentArt/src'\n",
        "else:\n",
        "    # Locally, it's ../src relative to notebooks/\n",
        "    src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "\n",
        "if src_path not in sys.path:\n",
        "    sys.path.append(src_path)\n",
        "\n",
        "from utils import get_device, clear_memory\n",
        "\n",
        "device = get_device()\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def load_scheduler(pipeline, scheduler_name=\"Euler A\"):\n",
        "    if scheduler_name == \"Euler A\":\n",
        "        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
        "    print(f\"Scheduler set to: {scheduler_name}\")\n",
        "\n",
        "negative_prompt = \"photorealistic, realistic, photograph, 3d render, messy, blurry, low quality, bad art, ugly, sketch, grainy, unfinished, chromatic aberration\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOFUC9bpyrow"
      },
      "source": [
        "### Kriteria 1: Text-to-Image (T2I)\n",
        "#### Basic: Simple Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMxc4DTkyrox"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe_t2i = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "load_scheduler(pipe_t2i, \"Euler A\")\n",
        "\n",
        "prompt = \"A futuristic city in the style of cyberpunk, vivid neon lights, high detail\"\n",
        "seed = 222\n",
        "generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "image = pipe_t2i(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "os.makedirs(\"../outputs\", exist_ok=True)\n",
        "image.save(\"../outputs/basic_t2i.png\")\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmWt4EWyrox"
      },
      "source": [
        "#### Skilled: Experimentation (Guidance Scale & Steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PDoxdeyrox"
      },
      "outputs": [],
      "source": [
        "# Experimentation on Guidance Scale (3-20) and Steps (10-50)\n",
        "guidance_scales = [3, 7, 15, 20]\n",
        "inference_steps = [10, 30, 50]\n",
        "exp_prompt = \"A majestic forest with magical glowing plants, digital art style\"\n",
        "\n",
        "fig, axes = plt.subplots(len(inference_steps), len(guidance_scales), figsize=(20, 15))\n",
        "\n",
        "for i, steps in enumerate(inference_steps):\n",
        "    for j, scale in enumerate(guidance_scales):\n",
        "        print(f\"Generating with Steps: {steps}, Scale: {scale}\")\n",
        "        generator = torch.Generator(device=device).manual_seed(222)\n",
        "        img = pipe_t2i(\n",
        "            prompt=exp_prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=scale,\n",
        "            generator=generator\n",
        ").images[0]\n",
        "        img.save(f\"../outputs/exp_steps{steps}_gs{scale}.png\")\n",
        "        axes[i, j].imshow(img)\n",
        "        axes[i, j].set_title(f\"Steps: {steps}, GS: {scale}\")\n",
        "        axes[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6xojAwNyroy"
      },
      "source": [
        "#### Advanced: Two-Stage Generation (Base + Refiner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsduNuMIyroy"
      },
      "outputs": [],
      "source": [
        "# Load Img2Img for refinement phase\n",
        "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Stage 1: Base Generation\n",
        "generator = torch.Generator(device=device).manual_seed(222)\n",
        "base_image = pipe_t2i(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, intricate armor\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "# Stage 2: Refinement (Denoising 0.8)\n",
        "refined_image = pipe_img2img(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, extreme armor detail, 4k, masterpiece\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=base_image.resize((768, 768)),\n",
        "    strength=0.8,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=8.0,\n",
        "    generator=torch.Generator(device=device).manual_seed(222)\n",
        ").images[0]\n",
        "\n",
        "refined_image.save(\"../outputs/advanced_refined.png\")\n",
        "refined_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaP5-DGSyroy"
      },
      "source": [
        "### Kriteria 2: Inpainting & Outpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nuMwAb_yroy"
      },
      "outputs": [],
      "source": [
        "inpaint_model_id = \"runwayml/stable-diffusion-inpainting\"\n",
        "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    inpaint_model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Manual Masking Demo\n",
        "init_image = Image.new(\"RGB\", (512, 512), (100, 100, 100)) # Grey background\n",
        "mask_image = Image.new(\"RGB\", (512, 512), (0, 0, 0)) # Black mask (do not change)\n",
        "draw = ImageDraw.Draw(mask_image)\n",
        "draw.rectangle([128, 128, 384, 384], fill=\"white\") # White area = change this!\n",
        "\n",
        "generator_inpaint = torch.Generator(device=device).manual_seed(9)\n",
        "\n",
        "inpainted_result = pipe_inpaint(\n",
        "    prompt=\"A majestic golden phoenix bird rising from flames\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=init_image,\n",
        "    mask_image=mask_image,\n",
        "    num_inference_steps=30,\n",
        "    generator=generator_inpaint\n",
        ").images[0]\n",
        "\n",
        "inpainted_result.save(\"../outputs/inpainted_result.png\")\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,3,1); plt.imshow(init_image); plt.title(\"Init\")\n",
        "plt.subplot(1,3,2); plt.imshow(mask_image); plt.title(\"Mask\")\n",
        "plt.subplot(1,3,3); plt.imshow(inpainted_result); plt.title(\"Result\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSEvkGqyroy"
      },
      "source": [
        "#### Zoom-Out (Outpainting) Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gJ71u0Jyroz"
      },
      "outputs": [],
      "source": [
        "def outpaint_prepare(image, pixels=128):\n",
        "    w, h = image.size\n",
        "    new_w = w + pixels\n",
        "    canvas = Image.new(\"RGB\", (new_w, h), (255, 255, 255))\n",
        "    canvas.paste(image, (0, 0))\n",
        "\n",
        "    mask = Image.new(\"RGB\", (new_w, h), (0, 0, 0))\n",
        "    mask_draw = ImageDraw.Draw(mask)\n",
        "    mask_draw.rectangle([w, 0, new_w, h], fill=\"white\")\n",
        "\n",
        "    return canvas, mask\n",
        "\n",
        "source_img = Image.open(\"../outputs/basic_t2i.png\").resize((512, 512))\n",
        "canvas, mask = outpaint_prepare(source_img)\n",
        "\n",
        "outpainted = pipe_inpaint(\n",
        "    prompt=\"A futuristic neon city street extending into the distance, cybernetic details\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=canvas,\n",
        "    mask_image=mask,\n",
        "    num_inference_steps=30,\n",
        "    generator=torch.Generator(device=device).manual_seed(9)\n",
        ").images[0]\n",
        "\n",
        "outpainted.save(\"../outputs/outpainted_result.png\")\n",
        "outpainted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIuoXnxeyroz"
      },
      "source": [
        "### Kriteria 3: Streamlit Interface Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjVrWV-iyroz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# Directly append the absolute Colab path and the exact relative path for local Jupyter\n",
        "colab_path = '/content/LatentArt/src'\n",
        "local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if os.path.exists(colab_path) and colab_path not in sys.path:\n",
        "    sys.path.append(colab_path)\n",
        "elif os.path.exists(local_path) and local_path not in sys.path:\n",
        "    sys.path.append(local_path)\n",
        "print(\"Streamlit setup would use the following structure in a .py file:\")\n",
        "print(\"\"\"\n",
        "import streamlit as st\n",
        "from streamlit_drawable_canvas import st_canvas\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "st.set_page_config(layout='wide')\n",
        "tab1, tab2 = st.tabs(['Text-to-Image', 'Inpaint & Outpaint'])\n",
        "\n",
        "with tab1:\n",
        "    # Batching logic 2x2 grid\n",
        "    pass\n",
        "\n",
        "with tab2:\n",
        "    # Canvas for masking logic\n",
        "    pass\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}