{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng0PGSLdyror"
      },
      "source": [
        "# Project LatentArt: LatentArt Submission\n",
        "## Level: ADVANCED\n",
        "\n",
        "This notebook documents the implementation and experimentation for the Image Generation Submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7qBoxz4yrou"
      },
      "source": [
        "### Colab Initialization\n",
        "This cell automatically mounts Google Drive and installs requirements if running in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKaIP9bnyrow"
      },
      "source": [
        "### Setup Environment & Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "cXSf53Rcyrow",
        "outputId": "0a265941-7568-4b65-e0ea-5adb0b0061f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/models/transformers/transformer_kandinsky.py:168: UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
            "  @torch.autocast(device_type=\"cuda\", dtype=torch.float32)\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/models/transformers/transformer_kandinsky.py:272: UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
            "  @torch.autocast(device_type=\"cuda\", dtype=torch.float32)\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading utils.py directly to /content...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1513824789.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'google.colab'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading utils.py directly to /content...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://raw.githubusercontent.com/urobin84/LatentArt/main/src/utils.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/utils.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/content'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    631\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sys\n",
        "import gc\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline, StableDiffusionImg2ImgPipeline, EulerAncestralDiscreteScheduler\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- BULLETPROOF COLAB FIX ---\n",
        "# Instead of pathing issues, we just read the raw github file for utils.py and write it locally\n",
        "import os\n",
        "import urllib.request\n",
        "if 'google.colab' in sys.modules:\n",
        "    print(\"Downloading utils.py directly to /content...\")\n",
        "    urllib.request.urlretrieve('https://raw.githubusercontent.com/urobin84/LatentArt/main/src/utils.py', '/content/utils.py')\n",
        "    if '/content' not in sys.path:\n",
        "        sys.path.append('/content')\n",
        "else:\n",
        "    import os\n",
        "    local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "    if os.path.exists(local_path) and local_path not in sys.path:\n",
        "        sys.path.append(local_path)\n",
        "\n",
        "from utils import get_device, clear_memory\n",
        "\n",
        "device = get_device()\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "def load_scheduler(pipeline, scheduler_name=\"Euler A\"):\n",
        "    if scheduler_name == \"Euler A\":\n",
        "        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
        "    print(f\"Scheduler set to: {scheduler_name}\")\n",
        "\n",
        "negative_prompt = \"photorealistic, realistic, photograph, 3d render, messy, blurry, low quality, bad art, ugly, sketch, grainy, unfinished, chromatic aberration\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOFUC9bpyrow"
      },
      "source": [
        "### Kriteria 1: Text-to-Image (T2I)\n",
        "#### Basic: Simple Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMxc4DTkyrox"
      },
      "outputs": [],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe_t2i = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "load_scheduler(pipe_t2i, \"Euler A\")\n",
        "\n",
        "prompt = \"A futuristic city in the style of cyberpunk, vivid neon lights, high detail\"\n",
        "seed = 222\n",
        "generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "image = pipe_t2i(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "os.makedirs(\"../outputs\", exist_ok=True)\n",
        "image.save(\"../outputs/basic_t2i.png\")\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKmWt4EWyrox"
      },
      "source": [
        "#### Skilled: Experimentation (Guidance Scale & Steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PDoxdeyrox"
      },
      "outputs": [],
      "source": [
        "# Experimentation on Guidance Scale (3-20) and Steps (10-50)\n",
        "guidance_scales = [3, 7, 15, 20]\n",
        "inference_steps = [10, 30, 50]\n",
        "exp_prompt = \"A majestic forest with magical glowing plants, digital art style\"\n",
        "\n",
        "fig, axes = plt.subplots(len(inference_steps), len(guidance_scales), figsize=(20, 15))\n",
        "\n",
        "for i, steps in enumerate(inference_steps):\n",
        "    for j, scale in enumerate(guidance_scales):\n",
        "        print(f\"Generating with Steps: {steps}, Scale: {scale}\")\n",
        "        generator = torch.Generator(device=device).manual_seed(222)\n",
        "        img = pipe_t2i(\n",
        "            prompt=exp_prompt,\n",
        "            negative_prompt=negative_prompt,\n",
        "            num_inference_steps=steps,\n",
        "            guidance_scale=scale,\n",
        "            generator=generator\n",
        ").images[0]\n",
        "        img.save(f\"../outputs/exp_steps{steps}_gs{scale}.png\")\n",
        "        axes[i, j].imshow(img)\n",
        "        axes[i, j].set_title(f\"Steps: {steps}, GS: {scale}\")\n",
        "        axes[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6xojAwNyroy"
      },
      "source": [
        "#### Advanced: Two-Stage Generation (Base + Refiner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsduNuMIyroy"
      },
      "outputs": [],
      "source": [
        "# Load Img2Img for refinement phase\n",
        "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Stage 1: Base Generation\n",
        "generator = torch.Generator(device=device).manual_seed(222)\n",
        "base_image = pipe_t2i(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, intricate armor\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=30,\n",
        "    guidance_scale=7.5,\n",
        "    generator=generator\n",
        ").images[0]\n",
        "\n",
        "# Stage 2: Refinement (Denoising 0.8)\n",
        "refined_image = pipe_img2img(\n",
        "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, extreme armor detail, 4k, masterpiece\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=base_image.resize((768, 768)),\n",
        "    strength=0.8,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=8.0,\n",
        "    generator=torch.Generator(device=device).manual_seed(222)\n",
        ").images[0]\n",
        "\n",
        "refined_image.save(\"../outputs/advanced_refined.png\")\n",
        "refined_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaP5-DGSyroy"
      },
      "source": [
        "### Kriteria 2: Inpainting & Outpainting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nuMwAb_yroy"
      },
      "outputs": [],
      "source": [
        "inpaint_model_id = \"runwayml/stable-diffusion-inpainting\"\n",
        "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    inpaint_model_id,\n",
        "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
        ").to(device)\n",
        "\n",
        "# Manual Masking Demo\n",
        "init_image = Image.new(\"RGB\", (512, 512), (100, 100, 100)) # Grey background\n",
        "mask_image = Image.new(\"RGB\", (512, 512), (0, 0, 0)) # Black mask (do not change)\n",
        "draw = ImageDraw.Draw(mask_image)\n",
        "draw.rectangle([128, 128, 384, 384], fill=\"white\") # White area = change this!\n",
        "\n",
        "generator_inpaint = torch.Generator(device=device).manual_seed(9)\n",
        "\n",
        "inpainted_result = pipe_inpaint(\n",
        "    prompt=\"A majestic golden phoenix bird rising from flames\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=init_image,\n",
        "    mask_image=mask_image,\n",
        "    num_inference_steps=30,\n",
        "    generator=generator_inpaint\n",
        ").images[0]\n",
        "\n",
        "inpainted_result.save(\"../outputs/inpainted_result.png\")\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,3,1); plt.imshow(init_image); plt.title(\"Init\")\n",
        "plt.subplot(1,3,2); plt.imshow(mask_image); plt.title(\"Mask\")\n",
        "plt.subplot(1,3,3); plt.imshow(inpainted_result); plt.title(\"Result\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBSEvkGqyroy"
      },
      "source": [
        "#### Zoom-Out (Outpainting) Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gJ71u0Jyroz"
      },
      "outputs": [],
      "source": [
        "def outpaint_prepare(image, pixels=128):\n",
        "    w, h = image.size\n",
        "    new_w = w + pixels\n",
        "    canvas = Image.new(\"RGB\", (new_w, h), (255, 255, 255))\n",
        "    canvas.paste(image, (0, 0))\n",
        "\n",
        "    mask = Image.new(\"RGB\", (new_w, h), (0, 0, 0))\n",
        "    mask_draw = ImageDraw.Draw(mask)\n",
        "    mask_draw.rectangle([w, 0, new_w, h], fill=\"white\")\n",
        "\n",
        "    return canvas, mask\n",
        "\n",
        "source_img = Image.open(\"../outputs/basic_t2i.png\").resize((512, 512))\n",
        "canvas, mask = outpaint_prepare(source_img)\n",
        "\n",
        "outpainted = pipe_inpaint(\n",
        "    prompt=\"A futuristic neon city street extending into the distance, cybernetic details\",\n",
        "    negative_prompt=negative_prompt,\n",
        "    image=canvas,\n",
        "    mask_image=mask,\n",
        "    num_inference_steps=30,\n",
        "    generator=torch.Generator(device=device).manual_seed(9)\n",
        ").images[0]\n",
        "\n",
        "outpainted.save(\"../outputs/outpainted_result.png\")\n",
        "outpainted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIuoXnxeyroz"
      },
      "source": [
        "### Kriteria 3: Streamlit Interface Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjVrWV-iyroz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "# Directly append the absolute Colab path and the exact relative path for local Jupyter\n",
        "colab_path = '/content/LatentArt/src'\n",
        "local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if os.path.exists(colab_path) and colab_path not in sys.path:\n",
        "    sys.path.append(colab_path)\n",
        "elif os.path.exists(local_path) and local_path not in sys.path:\n",
        "    sys.path.append(local_path)\n",
        "print(\"Streamlit setup would use the following structure in a .py file:\")\n",
        "print(\"\"\"\n",
        "import streamlit as st\n",
        "from streamlit_drawable_canvas import st_canvas\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "st.set_page_config(layout='wide')\n",
        "tab1, tab2 = st.tabs(['Text-to-Image', 'Inpaint & Outpaint'])\n",
        "\n",
        "with tab1:\n",
        "    # Batching logic 2x2 grid\n",
        "    pass\n",
        "\n",
        "with tab2:\n",
        "    # Canvas for masking logic\n",
        "    pass\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}