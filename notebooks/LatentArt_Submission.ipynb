{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "ng0PGSLdyror"
            },
            "source": [
                "# Project LatentArt: LatentArt Submission\n",
                "## Level: ADVANCED\n",
                "\n",
                "This notebook documents the implementation and experimentation for the Image Generation Submission."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "C7qBoxz4yrou"
            },
            "source": [
                "### Colab Initialization\n",
                "This cell automatically mounts Google Drive and installs requirements if running in Colab."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "tKaIP9bnyrow"
            },
            "source": [
                "### Setup Environment & Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 393
                },
                "executionInfo": {
                    "elapsed": 62,
                    "status": "error",
                    "timestamp": 1771822259088,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "cXSf53Rcyrow",
                "outputId": "3c78cf1b-8037-4da3-d879-e034c9c025dd"
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import sys\n",
                "import gc\n",
                "from diffusers import StableDiffusionPipeline, StableDiffusionInpaintPipeline, StableDiffusionImg2ImgPipeline, EulerAncestralDiscreteScheduler\n",
                "from PIL import Image, ImageDraw\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# --- BULLETPROOF COLAB FIX ---\n",
                "# Instead of pathing issues, we just read the raw github file for utils.py and write it locally\n",
                "import os\n",
                "import urllib.request\n",
                "if 'google.colab' in sys.modules:\n",
                "    print(\"Downloading utils.py directly to /content...\")\n",
                "    urllib.request.urlretrieve('https://raw.githubusercontent.com/urobin84/LatentArt/main/src/utils.py', '/content/utils.py')\n",
                "    if '/content' not in sys.path:\n",
                "        sys.path.append('/content')\n",
                "else:\n",
                "    import os\n",
                "    local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
                "    if os.path.exists(local_path) and local_path not in sys.path:\n",
                "        sys.path.append(local_path)\n",
                "\n",
                "from utils import get_device, clear_memory\n",
                "\n",
                "device = get_device()\n",
                "print(f\"\\nUsing device: {device}\")\n",
                "\n",
                "def load_scheduler(pipeline, scheduler_name=\"Euler A\"):\n",
                "    if scheduler_name == \"Euler A\":\n",
                "        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(pipeline.scheduler.config)\n",
                "    print(f\"Scheduler set to: {scheduler_name}\")\n",
                "\n",
                "negative_prompt = \"photorealistic, realistic, photograph, 3d render, messy, blurry, low quality, bad art, ugly, sketch, grainy, unfinished, chromatic aberration\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "pOFUC9bpyrow"
            },
            "source": [
                "### Kriteria 1: Text-to-Image (T2I)\n",
                "#### Basic: Simple Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3353,
                    "status": "aborted",
                    "timestamp": 1771822259106,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "BMxc4DTkyrox"
            },
            "outputs": [],
            "source": [
                "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
                "pipe_t2i = StableDiffusionPipeline.from_pretrained(\n",
                "    model_id,\n",
                "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
                ").to(device)\n",
                "\n",
                "load_scheduler(pipe_t2i, \"Euler A\")\n",
                "\n",
                "prompt = \"A futuristic city in the style of cyberpunk, vivid neon lights, high detail\"\n",
                "seed = 222\n",
                "generator = torch.Generator(device=device).manual_seed(seed)\n",
                "\n",
                "image = pipe_t2i(\n",
                "    prompt=prompt,\n",
                "    negative_prompt=negative_prompt,\n",
                "    num_inference_steps=30,\n",
                "    guidance_scale=7.5,\n",
                "    generator=generator\n",
                ").images[0]\n",
                "\n",
                "os.makedirs(\"../outputs\", exist_ok=True)\n",
                "image.save(\"../outputs/basic_t2i.png\")\n",
                "image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "MKmWt4EWyrox"
            },
            "source": [
                "#### Skilled: Experimentation (Guidance Scale & Steps)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3355,
                    "status": "aborted",
                    "timestamp": 1771822259108,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "P-PDoxdeyrox"
            },
            "outputs": [],
            "source": [
                "# Experimentation on Guidance Scale (3-20) and Steps (10-50)\n",
                "guidance_scales = [3, 7, 15, 20]\n",
                "inference_steps = [10, 30, 50]\n",
                "exp_prompt = \"A majestic forest with magical glowing plants, digital art style\"\n",
                "\n",
                "fig, axes = plt.subplots(len(inference_steps), len(guidance_scales), figsize=(20, 15))\n",
                "\n",
                "for i, steps in enumerate(inference_steps):\n",
                "    for j, scale in enumerate(guidance_scales):\n",
                "        print(f\"Generating with Steps: {steps}, Scale: {scale}\")\n",
                "        generator = torch.Generator(device=device).manual_seed(222)\n",
                "        img = pipe_t2i(\n",
                "            prompt=exp_prompt,\n",
                "            negative_prompt=negative_prompt,\n",
                "            num_inference_steps=steps,\n",
                "            guidance_scale=scale,\n",
                "            generator=generator\n",
                ").images[0]\n",
                "        img.save(f\"../outputs/exp_steps{steps}_gs{scale}.png\")\n",
                "        axes[i, j].imshow(img)\n",
                "        axes[i, j].set_title(f\"Steps: {steps}, GS: {scale}\")\n",
                "        axes[i, j].axis(\"off\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "clear_memory()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "H6xojAwNyroy"
            },
            "source": [
                "#### Advanced: Two-Stage Generation (Base + Refiner)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3358,
                    "status": "aborted",
                    "timestamp": 1771822259111,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "LsduNuMIyroy"
            },
            "outputs": [],
            "source": [
                "# Load Img2Img for refinement phase\n",
                "pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
                "    model_id,\n",
                "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
                ").to(device)\n",
                "\n",
                "# Stage 1: Base Generation\n",
                "generator = torch.Generator(device=device).manual_seed(222)\n",
                "base_image = pipe_t2i(\n",
                "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, intricate armor\",\n",
                "    negative_prompt=negative_prompt,\n",
                "    num_inference_steps=30,\n",
                "    guidance_scale=7.5,\n",
                "    generator=generator\n",
                ").images[0]\n",
                "\n",
                "# Stage 2: Refinement (Denoising 0.8)\n",
                "refined_image = pipe_img2img(\n",
                "    prompt=\"A detailed portrait of a fantasy knight, cinematic lighting, extreme armor detail, 4k, masterpiece\",\n",
                "    negative_prompt=negative_prompt,\n",
                "    image=base_image.resize((768, 768)),\n",
                "    strength=0.8,\n",
                "    num_inference_steps=50,\n",
                "    guidance_scale=8.0,\n",
                "    generator=torch.Generator(device=device).manual_seed(222)\n",
                ").images[0]\n",
                "\n",
                "refined_image.save(\"../outputs/advanced_refined.png\")\n",
                "refined_image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "XaP5-DGSyroy"
            },
            "source": [
                "### Kriteria 2: Inpainting & Outpainting"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3358,
                    "status": "aborted",
                    "timestamp": 1771822259112,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "3nuMwAb_yroy"
            },
            "outputs": [],
            "source": [
                "inpaint_model_id = \"runwayml/stable-diffusion-inpainting\"\n",
                "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
                "    inpaint_model_id,\n",
                "    torch_dtype=torch.float16 if device != \"cpu\" else torch.float32\n",
                ").to(device)\n",
                "\n",
                "# Manual Masking Demo\n",
                "init_image = Image.new(\"RGB\", (512, 512), (100, 100, 100)) # Grey background\n",
                "mask_image = Image.new(\"RGB\", (512, 512), (0, 0, 0)) # Black mask (do not change)\n",
                "draw = ImageDraw.Draw(mask_image)\n",
                "draw.rectangle([128, 128, 384, 384], fill=\"white\") # White area = change this!\n",
                "\n",
                "generator_inpaint = torch.Generator(device=device).manual_seed(9)\n",
                "\n",
                "inpainted_result = pipe_inpaint(\n",
                "    prompt=\"A majestic golden phoenix bird rising from flames\",\n",
                "    negative_prompt=negative_prompt,\n",
                "    image=init_image,\n",
                "    mask_image=mask_image,\n",
                "    num_inference_steps=30,\n",
                "    generator=generator_inpaint\n",
                ").images[0]\n",
                "\n",
                "inpainted_result.save(\"../outputs/inpainted_result.png\")\n",
                "plt.figure(figsize=(10,5))\n",
                "plt.subplot(1,3,1); plt.imshow(init_image); plt.title(\"Init\")\n",
                "plt.subplot(1,3,2); plt.imshow(mask_image); plt.title(\"Mask\")\n",
                "plt.subplot(1,3,3); plt.imshow(inpainted_result); plt.title(\"Result\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "aBSEvkGqyroy"
            },
            "source": [
                "#### Zoom-Out (Outpainting) Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3371,
                    "status": "aborted",
                    "timestamp": 1771822259125,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "0gJ71u0Jyroz"
            },
            "outputs": [],
            "source": [
                "def outpaint_prepare(image, pixels=128):\n",
                "    w, h = image.size\n",
                "    new_w = w + pixels\n",
                "    canvas = Image.new(\"RGB\", (new_w, h), (255, 255, 255))\n",
                "    canvas.paste(image, (0, 0))\n",
                "\n",
                "    mask = Image.new(\"RGB\", (new_w, h), (0, 0, 0))\n",
                "    mask_draw = ImageDraw.Draw(mask)\n",
                "    mask_draw.rectangle([w, 0, new_w, h], fill=\"white\")\n",
                "\n",
                "    return canvas, mask\n",
                "\n",
                "source_img = Image.open(\"../outputs/basic_t2i.png\").resize((512, 512))\n",
                "canvas, mask = outpaint_prepare(source_img)\n",
                "\n",
                "outpainted = pipe_inpaint(\n",
                "    prompt=\"A futuristic neon city street extending into the distance, cybernetic details\",\n",
                "    negative_prompt=negative_prompt,\n",
                "    image=canvas,\n",
                "    mask_image=mask,\n",
                "    num_inference_steps=30,\n",
                "    generator=torch.Generator(device=device).manual_seed(9)\n",
                ").images[0]\n",
                "\n",
                "outpainted.save(\"../outputs/outpainted_result.png\")\n",
                "outpainted"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "CIuoXnxeyroz"
            },
            "source": [
                "### Kriteria 3: Streamlit Interface Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "executionInfo": {
                    "elapsed": 3372,
                    "status": "aborted",
                    "timestamp": 1771822259126,
                    "user": {
                        "displayName": "u robin",
                        "userId": "05365978292003248028"
                    },
                    "user_tz": -420
                },
                "id": "SjVrWV-iyroz"
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "# Directly append the absolute Colab path and the exact relative path for local Jupyter\n",
                "colab_path = '/content/LatentArt/src'\n",
                "local_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
                "if os.path.exists(colab_path) and colab_path not in sys.path:\n",
                "    sys.path.append(colab_path)\n",
                "elif os.path.exists(local_path) and local_path not in sys.path:\n",
                "    sys.path.append(local_path)\n",
                "print(\"Streamlit setup would use the following structure in a .py file:\")\n",
                "print(\"\"\"\n",
                "import streamlit as st\n",
                "from streamlit_drawable_canvas import st_canvas\n",
                "from diffusers import StableDiffusionPipeline\n",
                "\n",
                "st.set_page_config(layout='wide')\n",
                "tab1, tab2 = st.tabs(['Text-to-Image', 'Inpaint & Outpaint'])\n",
                "\n",
                "with tab1:\n",
                "    # Batching logic 2x2 grid\n",
                "    pass\n",
                "\n",
                "with tab2:\n",
                "    # Canvas for masking logic\n",
                "    pass\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}